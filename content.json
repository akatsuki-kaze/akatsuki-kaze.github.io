{"meta":{"title":"akatsuki kaze's blogs","subtitle":"","description":"a personal blog","author":"akatsuki kaze","url":"http://www.akatsuki-kaze.com.cn","root":"/"},"pages":[{"title":"categories","text":"RC往事这是robocon历史上（可能）第一个记录了很多robocon历史往事的仓库。所有人均可上传和访问。 MTI战队2025届ROBOCON排球机械以及部分上位机算法开源关于2025届排球的部分方案开源，包括迭代前的上位机算法和R1机械开源 一个图像二值化小玩具字面意思，可以快速选取二值化范围的小工具，也许某些时候会有点用处？","path":"categories/index.html","date":"11-19","excerpt":""},{"title":"about","text":"我是谁我是来自福建理工大学MTI战队的晓风，在战队中担任算法组组长，主要负责上位机算法的开发。 如果您想要与我联系QQ：1652107474E-mail:1652107474@qq.comgithub:akatsuki kazebilibili: 晓风是男孩子","path":"about/index.html","date":"11-19","excerpt":""},{"title":"tags","text":"","path":"tags/index.html","date":"11-20","excerpt":""}],"posts":[{"title":"cuda_install","text":"关于如何安装CUDA相关的神经网络环境序言其实关于如何安装，网上不论是简单还是方便的做法都已经有很多了。之所以写这篇文章主要是为了方便自己留档以及给小登传阅——不管怎么说有一个统一的资料存放总是很方便的，遂书写此教程送给我们可爱的小登们。 电脑常识普及首先，要参与神经网络，强化学习相关的东西，肯定是要对电脑有点基础的。因此正确认识电脑是非常必要的，这一章可能会非常长，花大量篇幅来讲述电脑相关的知识和常识。毕竟大部分学生高中毕业前都没碰过电脑啊！ 所以对于电脑常识的普及会是非常重要的，接下来让我们娓娓道来。 对于很多人而言，电脑和手机一样都是按下开机键就会亮起来的东西。但是你是否清楚，在按下开机按键后发生了什么？在你打游戏，听音乐的时候，你的电脑又在做什么？ 首先，我们要从——当然不太可能是第一台电脑说起——计算器说起。电脑从诞生之初就是为了辅助我们完成复杂的运算准备的。1+1&#x3D;2，这是还没出生的小朋友都知道的。但是，一堆数不清的1+1，2+2，就需要大量的时间去运算。因此人类创造了计算机来帮我们自动化的完成一些复杂的或者重复的工作。当然，以前的计算机和现在的计算机差别十分甚至九分的大，就不展开讨论了。现代的计算机，其功能性也远高于以前的计算机，但是总体原理并没有太大变化。对于计算机而言，既然他是负责进行计算的设备，那么首先它需要有一个能够进行计算的单元，而对于这个很重要的计算单元，我们称之为CPU——Center Processing Unit。CPU在计算机中的作用，主要是负责大部分计算，一个CPU一次只能处理一条计算任务，但是得益于一些后来技术的提升，CPU已经可以承担大部分计算工作了。那么，CPU既然要进行超高速的计算，就需要对大量数据进行处理。但是处理完的数据会存放在哪里呢？简单来说，其实就放在RAM里，也就是常说的“内存条”。就像工具永远是放在手边拿起来用最快，但是放在手边你总得把他放回架子上——RAM的速度很快，但是断电后会清除数据。因此，对于重要的计算结果，就需要一个能够长时间储存的地方——硬盘硬盘就是常说的存储，存储空间不够了也就是说硬盘需要加钱扩容咯！然而，随着时代发展，一项新的技术和需求出现了——三维渲染。虽然CPU计算速度和能力很强，但是三维的计算有一个特点——如果没有同时的大范围的渲染，三维的图像将会变得很卡，因为CPU只有线性的处理能力，并不能同时处理大量工作。因此，一项新的技术应运而生，那就是GPU——Graphics Processing Unit，GPU有一个特点就是可以进行大量的同时运算，因此很适合图像处理。但是同时，适合图像处理也意味着另外一件事——神经网络这种需要大量并行计算的算法。让我们回顾一下，CPU适合高速线性运算，GPU适合并行计算。然后就是关于CPU和GPU常见的厂家，CPU领域英特尔，AMD；GPU领域英伟达，AMD。其中我们着重讲述英伟达的GPU——RTX（GTX）系列显卡。大部分同学的电脑上应该都有一个绿色的GeForce小贴纸，这意味着你的电脑搭载了新型的英伟达游戏显卡。而英伟达十分重视AI领域发展，其深知GPU的并行计算优势，为了方便开发，他早有准备，做好了工具箱放在你手上，其名为CUDA Toolkit 。后文称工具集。 环境安装确定版本我们常用的onnx，pytorch框架都将会依赖于工具集和英伟达神经网络运行库cudnn。下文将以win和Ubuntu环境分别讲述安装。首先，确认好你需要进行安装的电脑的显卡驱动，一般而言都是安装好的，如图则是安装了驱动，若没有请按顺序阅读文章安装。首先，前往英伟达官网寻找适合自己的驱动，下载安装好以后，按win，在搜索框输入power，找到power shell，打开。输入nvidia-smi，找到CUDA Version，记下后面的版本号，这代表你能安装的最高的工具集版本。但是请注意！根据你所需要的项目安装正确的版本！而不是一味的跟着教程！接下来，打开工具集下载链接,找到合适的版本，点击进入，不能超过上述的&#96;&#96;&#96;nvidia-smi&#96;&#96;获取的版本。 下载完成后双击打开安装程序，设置好安装路径。个人建议直接按照默认路径，若不为默认路径则需要记下安装路径后续安装需要用到。接下来一路安装即可选择自定义安装全部勾选。新版本cuda有更新，多出来的选项可选可不选。记住你的cuda安装路径！如果是默认路径一般是C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\你的cuda版本安装完成后重启电脑，命令行输入nvcc -V,如果有如下图信息则是安装成功 安装cudnncudnn是英伟达显卡运行神经网络最重要的工具，并且与cuda版本严格对应。首先打开cudnn下载，首次使用可能需要注册账号，注册完根据自己的cuda版本下载cudnn库。下载时选择对应的zip压缩包，下载完后解压，会出现三个文件夹：将这三个文件夹的内容物复制到前文提到的cuda安装文件夹的同名文件夹内即可为cuDNN添加环境变量：找到环境变量-系统变量-path，分别将如下三个变量添加进去，完成安装。 ubuntu下安装其实仅一点不同：ubuntu安装cuda可以直接借助sh命令行安装看最下面两行，按下ctrl+alt+t唤起终端后分别输入就安装成功了，同样输入nvidia-smi，找到CUDA Version。由于使用ubuntu系统默认已经有不少计算机基础以及独立搜索解决问题的能力，因此本篇不再赘述，只引用一篇优秀的文章：文章链接其中gcc相关问题可以先不做解决，安装失败再处理。在ubuntu进行操作只需要记住：永远不要动你的内核，尽量不要动系统组件，否则后果自负。若对文章有疑惑可联系本人，侵权联系删除。","path":"2025/11/21/cuda-install/","date":"11-21","excerpt":"","tags":[{"name":"tutorial","slug":"tutorial","permalink":"http://www.akatsuki-kaze.com.cn/tags/tutorial/"}]},{"title":"the_past_of_curc_robocon","text":"RC往事rc历史上可能是第一个记录了“技术大佬”们鲜活日常的仓库","path":"2025/11/20/the-past-of-robocon/","date":"11-20","excerpt":"","tags":[{"name":"robocon","slug":"robocon","permalink":"http://www.akatsuki-kaze.com.cn/tags/robocon/"}]},{"title":"coworkers_for_KFS","text":"KFS数据集共创计划[TOC] 前言PS. 本文项目现已刊登至比赛组委会官方公众号 原文链接 在2026赛季的robocon比赛中，我们可以发现机器人在功夫卷轴上完成识别几乎是硬性需求，但是功夫卷轴种类繁多，光凭借一个队伍的视觉ldx和xdx，每种50张工作量也是巨大的。因此，本人决定发起一个数据集标注活动，将每种图片规定好标签等，然后汇总到github仓库，并且通过一些开源中附带的小工具针对不同队伍需求进行数据格式转换。同时保留了原始数据文件夹供各个队伍自行决定。由于采用yolo模型的人数较多，因此本人倡议使用yolo数据集格式（即txt坐标文件+原始图像+一个标签文件）。本项目不要求区分train和val，只需要标注完成后上传即可。希望Rc比赛可以有更好的开源氛围以及共创氛围。20251110更新：增加了马术分支，但是由于本人精力有限，目前需要助手帮助维护更新马术分支 一、数据采集注意事项由于比赛过程中，我们可能需要面对复杂的场景以及灯光干扰，因此本人建议在数据集中尽可能涉及大块纯色色块（绿色、红色或者蓝色）。可以考虑加入一些天花板为背景的图片作为应对灯光的抗干扰。若觉得模型数据仍然不理想，可以参考我校排球开源中的灯光抗干扰方案，但是未经验证不知可行性。数据集采集时，可以通过录制1080p30帧的视频，然后导入剪辑软件中。剪辑软件设置为导出640*640（yolo默认格式）视频，随后在格式工厂（或者其他工具中）导出为帧，然后摇两个小登开始标数据。 注：关于剪辑软件说明个人推荐：达芬奇(专业，免费的剪辑软件，适合让运营兼职的同时学习，也适合想要学习新技能的同学。同时本身也有强大的各种工具。如果有需要本人后续会录制简单说明)剪映(相对达芬奇，简单易上手，专业性并没有差很多，十分适合所有视觉组成员学习一下)finalcut(macOS专用，但是本人用的不多)PR为付费软件，处于支持正版角度考虑不建议购买使用，并且对于新手没有达芬奇好上手。必剪，本人不是很推荐的一款软件，但是如果有会使用的同学可以考虑使用。其余软件本人使用不多，是否采用还是以个人习惯为主看，本人仅以高中以及大一时期融媒体工作流相关经验提出观点。 二、数据集标注要求（一）标签要求&ensp;标签从零到一到32开始，并且每张图最好只出现一类标签！标注时，请框选整个KFS（若条件有限则只框选有颜色的部分）。标签顺序如图标注：上为甲骨、下为小篆，内容一致：武林至尊戈刀弓矢力德王帝天日月左上角的数字代表标签顺序（本来应从零开始，但是由于外包疏忽以及理解方便还是标注为1开始计数），标签建议在制作数据集之前就提前创建好或者使用本项目下的标签文件（targets文件夹内）。接下来会规范每一个标签的命名，从第一个开始： R_R1 B_R1 T_03 T_04 T_05 T_06 T_07 T_08 T_09 T_10 T_11 T_12 T_13 T_14 T_15 T_16 T_17 F_18 F_19 F_20 F_21 F_22 F_23 F_24 F_25 F_26 F_27 F_28 F_29 F_30 F_31 F_32 本意是可以让网络识别到单个字体，后续通过标签来判断真假。标注时请注意类别一定要全部添加，后续整理合并数据集时才不会混乱。 （二）关于数据集&ensp;如前文所说，本人倡议使用yolo数据集格式，因为本人接触到的队伍大多都使用yolo作为主要识别模型，因此本项目推荐使用yolo格式。若有其他格式需求可以使用转换工具。如果有需求，可以单独开设数据集格式文件夹以供使用。数据集最小数量要求为50张。 三、标注完成（一）整理数据集&ensp;将您的数据集标签与图片放置于同一文件夹下，命名为贵校缩写或者战队英文名（例如FJUT，MTI等），然后上传至对应的文件夹下。 （二）上传文件&ensp;提交PR至对应文件夹，文件夹结构如下 --+--labeled | +--orignal_datas | +--tools labeled为数据集对应存放处，打开即可看见多种数据集名字。请按照上述要求创建好学校名字文件夹后提交您的pr。如果发现pr没有及时采用请私聊骚扰本人。如果您有需求也可以通过悬赏提出issue，也请各位创作时注意数据集的均衡性，尽量保证r2的每一种方块数据数量是相等的。 四、下载数据集（一）下载&ensp;您可以通过各种方式下载，这里不再赘述 （二）使用&ensp;在本项目的tools文件夹下会有各种文件处理工具，具体使用说明请参阅tools下的readme文档。由于部分工具可能非本人上传，因此请谨慎使用或检查源码自行评估使用。上传的工具必须为c源码或python的py程序，上传工具源码必须可见！这是根本原则！在进行完数据集合并后，我建议您自行半随机抽取图像进行数据集的划分，因为不同学校拍摄环境不同，训练效果也不同，若均匀分配则可以使模型泛化能力更强。具体如何操作看您设计。 五、如何参与获取联系方式或参与讨论：&ensp;添加个人联系方式：1652107474（QQ）或者进入QQ群1065597020。 参与协作：&ensp;将您标注的数据集的图片（总览）以及数据集通过邮箱发给本人（1652107474@qq.com）,若您介意，只需要发送标注好的部分图像也可，本人将会在三个工作日内完成审核并且邀请您加入私有仓库协作，请在发送邮件时注明学校以及参加KFS标注协作，若审核不及时请在群内艾特一下本人。 六、碎碎念&ensp;由于这是多人共创项目，并且由于加入时间先后，队员数量等原因必然会产生各个学校上传数据集不同等的现象。例如本人队伍目前只有本人一位正式的视觉组成员，因此产出数据集必然是不同等的，如果您需要根据已有总量评估，请联系本人，我也会尽量配合您进行数据集数量评估。我也并未强制要求您将所有数据集上传，仅需要上传您认为值得上传的部分，希望参与本项目的学校可以对此做好心理准备&ensp;我仍然衷心希望RC可以是一个开放包容的比赛氛围。对于贡献较高的队伍在比赛时我们将会为其准备一些神秘小礼品以示心意。本项目仍然在完善阶段，欢迎踊跃参与。","path":"2025/11/20/coworkers-for-KFS/","date":"11-20","excerpt":"","tags":[{"name":"robocon","slug":"robocon","permalink":"http://www.akatsuki-kaze.com.cn/tags/robocon/"}]},{"title":"MTI_volleyball_opensource","text":"MTI战队视觉方案开源前言 在初步研究了排球比赛的规则之后，我们组内成员偏向于认为视觉方案在这次比赛中可能会有一个比较重要的作用。但是在实际比赛中，我们发现部分队伍因为灯光影响而放弃视觉方案。部分学校则是采取了风格特异的抗干扰方案排除灯光影响。例如某大学是采取了现场标记数据集，而另一个大学则是数据集一开始就使用蓝色为主的排球，由此达成抗干扰效果。尽管由于其他问题我们的视觉识别并未起到作用，但是鉴于实地测试表现我决定仍然将其开源。电控部分代码则开源在这个仓库。本代码在这里开源,在闲鱼购买请联系原作者1652107474@qq.com 一、代码功能综述 本代码结构为d415_ubuntu.py作为主程序，anti_light.py作为抗灯光部分，Serial_akatsuki_simple.py作为串口通讯相关的函数处理（包括数据内容以及编码发送），pid_akatsuki.py是用于跟踪的pid控制器。run.bat是为win环境准备的启动程序（win版本主程序为d415）。本代码不依赖ros，需求python版本3.9及以上，3.10经过测试稳定运行。要求库已经内置在requirementa.txt中。ubuntu需要使用python命令启动。程序启动时需要接入xinput支持的手柄，realsense d4系列带rgb摄像头（d410可以使用深度摄像头传输rgb流，d430不行），以及ch340（我们的方案是自带ch340的nrf24射频） 二、主函数代码解析 12行开始代码部分 pipeline = rs.pipeline() #定义流程pipeline config = rs.config() #定义配置config config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 60) #配置depth流 config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 60) #配置color流 profile = pipeline.start(config) #流程开始 align_to = rs.stream.color #与color流对齐 align = rs.align(align_to) 以上是realsense相关的初始化 # 全局变量,用于存储模型和摄像头对象 model = None cap = None track = 0 act_model = 0 # 用于控制动作的变量 X,Y,RIGHT_X,RIGHT_Y= 0,0,0,0 # 控制移动的变量 # 设置模型配置 script_dir = Path(__file__).parent file_path = script_dir / &#39;model&#39; / &#39;yolo11s.pt&#39; model_config = { &#39;model_path&#39;: str(file_path), &#39;download_url&#39;: &#39;https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt&#39; } # 推理参数 predict_config = { &#39;conf_thres&#39;: 0.6, &#39;iou_thres&#39;: 0.2, &#39;imgsz&#39;: 640, &#39;line_width&#39;: 2, &#39;device&#39;: &#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39; } def init_inference(confidence, iou): global model # 加载 YOLO 模型 model = YOLO(model_config[&#39;model_path&#39;]).to(predict_config[&#39;device&#39;]) return True 这里是关于yolo推理部分的初始化，其中X,Y,RIGHT_X,RIGHT_Y= 0,0,0,0会在稍后作为传入信息数组的变量，提前进行全局声明和初始化。model_config是模型的路径，仍然保留了网络下载路径，但是实际代码中没有相关功能。init_inference函数用于初始化模型，若初始化成功会返回true。接下来直接转到识别部分 global frame1,rgb,center1 # 读取摄像头的帧 frame1 = rgb.copy() # 使用 YOLO 模型进行推理,并传入置信度和 IoU 阈值 results1 = model(frame1, conf=0.5, iou=0.7) detect_len = len(results1[0].boxes) #获取检测结果的长度 # 获取检测结果的坐标并绘制检测框 boxes1 = [] if detect_len != 0: for r in results1: for box in r.boxes: xyxy = box.xyxy[0].cpu().numpy().astype(int) boxes1.append(xyxy) cv2.rectangle(frame1, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), (0, 255, 0), 2) center1 = np.array([x_center1, y_center1]) else: print(&quot;未检测到目标&quot;) center1 = np.array([320, 5]) 这段代码对应yolo的识别部分。由于anti_light代码在nuc上，后续会惊醒补充。接下来来到代码的主函数部分，108行开始： global actX,act_dis x_center1 = 320 y_center1 = 240 center1 = np.array([x_center1, y_center1]) actX = pid.ProportionalPID( kd= 260, ki= 0, kp= 180, deadband= 0.01 ) act_dis = pid.ProportionalPID( kd= 220, ki= 0, kp= 160, deadband= 0.001 ) 提前声明部分变量，实例化需要用到的两个pid控制器（对应水平和竖直方向）接下来是串口选择部分，这个部分目前只有win版本有效，ubuntu版本已经删除。选择串口时，用手柄的hat（十字键）进行选择，上下为加减5，左右加减1（ubuntu版本功能为上下加减1）。选择完成后，按下手柄A按键确定串口。170行的asyncio.run(detect()) #协程推理使用了asyncio库进行协程，达到优化推理产生的控制延迟的效果。实际上发现在一定程度上也优化了推理性能。173行开始的这段代码中 x = int(center1[0]) y = int(center1[1]) #(x, y)点的真实深度值 dis = aligned_depth_frame.get_distance(x, y) #(x, y)点在相机坐标系下的真实值,为一个三维向量。其中camera_coordinate[2]仍为dis,camera_coordinate[0]和camera_coordinate[1]为相机坐标系下的xy真实距离。 camera_coordinate = rs.rs2_deproject_pixel_to_point(depth_intrin, [x, y], dis) if camera_coordinate != (0.0,0.0,0.0): last_coordinate = camera_coordinate print(camera_coordinate) else: print(last_coordinate) 这段代码会对像素坐标进行获取。由于深度摄像头在距离过近的目标识别会输出0，0，0的坐标值，因此会对目标最后的位置进行检测，决定是否写入坐标值 接下来是198行，对应动作组 # 执行动作组 if sc.joystick.get_button(13) == 1: if camera_coordinate[2] !=0.0: act_group = 1 else: act_group = 2 else: act_group = 0 action_group(act_group) act_group = 0 这段代码在手柄左摇杆按下时会进入自动跟踪状态，同时通过目标不同状态选择动作组。在执行程序action_group结束后act_group会归为0，防止动作重复执行。 sc.time.sleep(0.01) robot.send() 这段为发送所有的数据组，sleep为阻塞线程，防止串口发送频率太快导致报错","path":"2025/11/19/posts/","date":"11-19","excerpt":"","tags":[{"name":"robocon","slug":"robocon","permalink":"http://www.akatsuki-kaze.com.cn/tags/robocon/"}]}],"categories":[],"tags":[{"name":"tutorial","slug":"tutorial","permalink":"http://www.akatsuki-kaze.com.cn/tags/tutorial/"},{"name":"robocon","slug":"robocon","permalink":"http://www.akatsuki-kaze.com.cn/tags/robocon/"}]}